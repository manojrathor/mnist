{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_MLP_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manojrathor/mnist/blob/master/mnist_MLP_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYT2bmn47YKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q0oOgqF-Ohl",
        "colab_type": "code",
        "outputId": "bc5b7fef-f7a5-4afd-d750-322cf4fc3da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIJ8vlOB-0WV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fafd0434-ce8d-41f7-a8c9-a0313d49001a"
      },
      "source": [
        "# import libraries\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rnpj56I_KkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "020986c3-bbe2-4e36-a698-2dd17b0c61e0"
      },
      "source": [
        "# load dataset\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3uSZ0DNENBS",
        "colab_type": "code",
        "outputId": "b216c13a-3f59-4881-969e-22b87802c4cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.imshow(x_train[8])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaIMv1SU4ZeKMvxSUf8Pppy63sRz9OcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_Uo9epu_Tw2",
        "colab_type": "code",
        "outputId": "51c3da42-b06c-4d9f-8cd3-82b262a692d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# computer the shape of the train and test dataser\n",
        "x_train.shape, y_train.shape, x_test.shape,y_test.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usdEBXOAEQw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2])\n",
        "y_train = to_categorical(y_train,10)\n",
        "y_test = to_categorical(y_test,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgn_BfMkKnSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enYHl5ILGPsK",
        "colab_type": "code",
        "outputId": "a3924b36-5564-4e16-9a01-9160aa0024af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjyaA64XGXY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "5cc7ee61-9de9-40aa-91db-3cc53576d63f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64,activation = 'relu',input_shape = (784,)))\n",
        "model.add(Dense(10,activation = 'softmax'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0713 12:30:02.471342 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0713 12:30:02.535032 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0713 12:30:02.543671 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKbl5xhBHlTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ad51a0dd-39f1-47ad-c918-e84f7295c4a3"
      },
      "source": [
        "# Compile a model\n",
        "model.compile(optimizer = 'sgd',loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0713 12:30:07.785348 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0713 12:30:07.822496 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAlwDID1IS1P",
        "colab_type": "code",
        "outputId": "b935f9c4-d4b0-4cda-e2bb-c21b930841d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fir the model to training data\n",
        "history = model.fit(x_train,y_train,validation_split = 0.2, epochs =50, batch_size = 64)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0713 12:30:11.889022 139647535216512 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0713 12:30:11.950438 139647535216512 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 7s 155us/step - loss: 1.0150 - acc: 0.7490 - val_loss: 0.5167 - val_acc: 0.8761\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 3s 69us/step - loss: 0.4703 - acc: 0.8786 - val_loss: 0.3889 - val_acc: 0.8970\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 3s 68us/step - loss: 0.3902 - acc: 0.8932 - val_loss: 0.3432 - val_acc: 0.9052\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 3s 69us/step - loss: 0.3526 - acc: 0.9011 - val_loss: 0.3195 - val_acc: 0.9107\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 3s 69us/step - loss: 0.3287 - acc: 0.9078 - val_loss: 0.2998 - val_acc: 0.9166\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 3s 68us/step - loss: 0.3109 - acc: 0.9131 - val_loss: 0.2866 - val_acc: 0.9193\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2964 - acc: 0.9174 - val_loss: 0.2760 - val_acc: 0.9224\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2844 - acc: 0.9201 - val_loss: 0.2657 - val_acc: 0.9265\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2738 - acc: 0.9232 - val_loss: 0.2576 - val_acc: 0.9278\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.2639 - acc: 0.9264 - val_loss: 0.2502 - val_acc: 0.9293\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2552 - acc: 0.9291 - val_loss: 0.2429 - val_acc: 0.9311\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2472 - acc: 0.9312 - val_loss: 0.2365 - val_acc: 0.9333\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.2395 - acc: 0.9336 - val_loss: 0.2302 - val_acc: 0.9347\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2322 - acc: 0.9355 - val_loss: 0.2238 - val_acc: 0.9371\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2255 - acc: 0.9373 - val_loss: 0.2188 - val_acc: 0.9381\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2192 - acc: 0.9392 - val_loss: 0.2132 - val_acc: 0.9410\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.2134 - acc: 0.9403 - val_loss: 0.2085 - val_acc: 0.9419\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2075 - acc: 0.9424 - val_loss: 0.2042 - val_acc: 0.9437\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.2023 - acc: 0.9437 - val_loss: 0.2013 - val_acc: 0.9448\n",
            "Epoch 20/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1976 - acc: 0.9450 - val_loss: 0.1959 - val_acc: 0.9457\n",
            "Epoch 21/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1930 - acc: 0.9461 - val_loss: 0.1923 - val_acc: 0.9468\n",
            "Epoch 22/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1884 - acc: 0.9474 - val_loss: 0.1898 - val_acc: 0.9473\n",
            "Epoch 23/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1843 - acc: 0.9484 - val_loss: 0.1861 - val_acc: 0.9488\n",
            "Epoch 24/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1804 - acc: 0.9493 - val_loss: 0.1832 - val_acc: 0.9497\n",
            "Epoch 25/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1766 - acc: 0.9506 - val_loss: 0.1800 - val_acc: 0.9509\n",
            "Epoch 26/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1731 - acc: 0.9516 - val_loss: 0.1776 - val_acc: 0.9504\n",
            "Epoch 27/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1695 - acc: 0.9522 - val_loss: 0.1754 - val_acc: 0.9513\n",
            "Epoch 28/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1663 - acc: 0.9537 - val_loss: 0.1729 - val_acc: 0.9523\n",
            "Epoch 29/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1633 - acc: 0.9542 - val_loss: 0.1708 - val_acc: 0.9534\n",
            "Epoch 30/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1602 - acc: 0.9551 - val_loss: 0.1689 - val_acc: 0.9532\n",
            "Epoch 31/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1574 - acc: 0.9557 - val_loss: 0.1662 - val_acc: 0.9547\n",
            "Epoch 32/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1545 - acc: 0.9566 - val_loss: 0.1639 - val_acc: 0.9553\n",
            "Epoch 33/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1519 - acc: 0.9573 - val_loss: 0.1621 - val_acc: 0.9545\n",
            "Epoch 34/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1495 - acc: 0.9581 - val_loss: 0.1610 - val_acc: 0.9550\n",
            "Epoch 35/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1469 - acc: 0.9589 - val_loss: 0.1586 - val_acc: 0.9563\n",
            "Epoch 36/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1445 - acc: 0.9595 - val_loss: 0.1567 - val_acc: 0.9567\n",
            "Epoch 37/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1422 - acc: 0.9599 - val_loss: 0.1557 - val_acc: 0.9564\n",
            "Epoch 38/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1400 - acc: 0.9608 - val_loss: 0.1543 - val_acc: 0.9568\n",
            "Epoch 39/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1377 - acc: 0.9616 - val_loss: 0.1525 - val_acc: 0.9574\n",
            "Epoch 40/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1355 - acc: 0.9622 - val_loss: 0.1510 - val_acc: 0.9580\n",
            "Epoch 41/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1338 - acc: 0.9624 - val_loss: 0.1489 - val_acc: 0.9583\n",
            "Epoch 42/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1316 - acc: 0.9632 - val_loss: 0.1483 - val_acc: 0.9586\n",
            "Epoch 43/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1297 - acc: 0.9640 - val_loss: 0.1463 - val_acc: 0.9596\n",
            "Epoch 44/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1278 - acc: 0.9646 - val_loss: 0.1445 - val_acc: 0.9595\n",
            "Epoch 45/50\n",
            "48000/48000 [==============================] - 3s 66us/step - loss: 0.1261 - acc: 0.9650 - val_loss: 0.1438 - val_acc: 0.9600\n",
            "Epoch 46/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1244 - acc: 0.9655 - val_loss: 0.1423 - val_acc: 0.9600\n",
            "Epoch 47/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1226 - acc: 0.9659 - val_loss: 0.1408 - val_acc: 0.9605\n",
            "Epoch 48/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1208 - acc: 0.9666 - val_loss: 0.1407 - val_acc: 0.9614\n",
            "Epoch 49/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1192 - acc: 0.9670 - val_loss: 0.1393 - val_acc: 0.9622\n",
            "Epoch 50/50\n",
            "48000/48000 [==============================] - 3s 65us/step - loss: 0.1175 - acc: 0.9673 - val_loss: 0.1375 - val_acc: 0.9611\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fm5gf6IjxU",
        "colab_type": "code",
        "outputId": "6a623f51-3398-4ab1-f3ce-28f77129682a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.evaluate(x_test,y_test,batch_size = 128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 18us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13115456853806973, 0.9615]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUNV3TlZH6V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}